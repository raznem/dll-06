{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1, 1))\n",
    "display.start()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_2(model, num_episodes=100):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_episodes: (int) number of episodes\n",
    "    :return: (float) Mean reward for the given number of episodes\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    obs = env.reset()\n",
    "    for i in range(num_episodes):\n",
    "        episode_rewards.append(0.0)\n",
    "        done = False\n",
    "        while not done:\n",
    "            # _states are only useful when using LSTM policies\n",
    "            action, _states = model.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            # Stats\n",
    "            episode_rewards[-1] += reward\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "    # Compute mean reward for the last 100 episodes\n",
    "    mean_100ep_reward = round(np.mean(episode_rewards), 1)\n",
    "    print(\"Mean reward:\", mean_100ep_reward, \"Num episodes:\", len(episode_rewards))\n",
    "    return mean_100ep_reward, episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common import make_vec_env, set_global_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BipedalWalker-v2')\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0029015052  |\n",
      "| clipfrac           | 0.020999998   |\n",
      "| explained_variance | -0.00946      |\n",
      "| fps                | 872           |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 5.68657       |\n",
      "| policy_loss        | -0.0063695135 |\n",
      "| serial_timesteps   | 2000          |\n",
      "| time_elapsed       | 1.91e-06      |\n",
      "| total_timesteps    | 2000          |\n",
      "| value_loss         | 92.702614     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0027484435 |\n",
      "| clipfrac           | 0.019374998  |\n",
      "| explained_variance | 0.268        |\n",
      "| fps                | 981          |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 5.7017155    |\n",
      "| policy_loss        | -0.002791639 |\n",
      "| serial_timesteps   | 20000        |\n",
      "| time_elapsed       | 18.6         |\n",
      "| total_timesteps    | 20000        |\n",
      "| value_loss         | 0.15041742   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.005454379   |\n",
      "| clipfrac           | 0.06862499    |\n",
      "| explained_variance | 0.00451       |\n",
      "| fps                | 978           |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 5.7554145     |\n",
      "| policy_loss        | -0.0037535292 |\n",
      "| serial_timesteps   | 40000         |\n",
      "| time_elapsed       | 39.1          |\n",
      "| total_timesteps    | 40000         |\n",
      "| value_loss         | 62.56365      |\n",
      "--------------------------------------\n",
      "CPU times: user 1min 8s, sys: 6.2 s, total: 1min 14s\n",
      "Wall time: 51.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fc8206bb990>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = PPO2(MlpPolicy, env, n_steps=2000, verbose=1, nminibatches=20)\n",
    "model.learn(total_timesteps=50000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common import set_global_seeds, make_vec_env\n",
    "from stable_baselines import PPO2\n",
    "\n",
    "def make_env(env_id, rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environments you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_global_seeds(seed)\n",
    "    return _init\n",
    "\n",
    "\n",
    "# Stable Baselines provides you with make_vec_env() helper\n",
    "# which does exactly the previous steps for you:\n",
    "# env = make_vec_env(env_id, n_envs=num_cpu, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BipedalWalker-v2\"\n",
    "num_cpu = 20  # Number of processes to use\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0032459039  |\n",
      "| clipfrac           | 0.029124996   |\n",
      "| explained_variance | 0.00101       |\n",
      "| fps                | 2580          |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 5.6822343     |\n",
      "| policy_loss        | -0.0046145217 |\n",
      "| serial_timesteps   | 100           |\n",
      "| time_elapsed       | 3.1e-06       |\n",
      "| total_timesteps    | 2000          |\n",
      "| value_loss         | 338.62793     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0036413774  |\n",
      "| clipfrac           | 0.03612499    |\n",
      "| explained_variance | 0.257         |\n",
      "| fps                | 4691          |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 5.7550087     |\n",
      "| policy_loss        | -0.0044008223 |\n",
      "| serial_timesteps   | 1000          |\n",
      "| time_elapsed       | 4.52          |\n",
      "| total_timesteps    | 20000         |\n",
      "| value_loss         | 0.13658616    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002196551  |\n",
      "| clipfrac           | 0.015249999  |\n",
      "| explained_variance | -0.00624     |\n",
      "| fps                | 4048         |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 5.7437406    |\n",
      "| policy_loss        | -0.005457635 |\n",
      "| serial_timesteps   | 2000         |\n",
      "| time_elapsed       | 9.1          |\n",
      "| total_timesteps    | 40000        |\n",
      "| value_loss         | 61.66505     |\n",
      "-------------------------------------\n",
      "CPU times: user 19 s, sys: 3.61 s, total: 22.6 s\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fc718af6390>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = PPO2(MlpPolicy, env, n_steps=int(2000/num_cpu), verbose=1, nminibatches=20)\n",
    "model.learn(total_timesteps=50000, log_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mp train for 500k ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"BipedalWalker-v2\"\n",
    "num_cpu = 20  # Number of processes to use\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0023981573  |\n",
      "| clipfrac           | 0.016499996   |\n",
      "| explained_variance | -0.000227     |\n",
      "| fps                | 2894          |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 5.671473      |\n",
      "| policy_loss        | -0.0050848573 |\n",
      "| serial_timesteps   | 100           |\n",
      "| time_elapsed       | 3.58e-06      |\n",
      "| total_timesteps    | 2000          |\n",
      "| value_loss         | 249.08528     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00409021   |\n",
      "| clipfrac           | 0.04724998   |\n",
      "| explained_variance | 0.146        |\n",
      "| fps                | 4502         |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 5.7100744    |\n",
      "| policy_loss        | -0.004566309 |\n",
      "| serial_timesteps   | 1000         |\n",
      "| time_elapsed       | 4.69         |\n",
      "| total_timesteps    | 20000        |\n",
      "| value_loss         | 0.17812183   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0022745072  |\n",
      "| clipfrac           | 0.018749993   |\n",
      "| explained_variance | 0.0175        |\n",
      "| fps                | 4282          |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 5.6625905     |\n",
      "| policy_loss        | -0.0028935524 |\n",
      "| serial_timesteps   | 2000          |\n",
      "| time_elapsed       | 9.37          |\n",
      "| total_timesteps    | 40000         |\n",
      "| value_loss         | 68.998604     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0045863944 |\n",
      "| clipfrac           | 0.050750006  |\n",
      "| explained_variance | 0.0426       |\n",
      "| fps                | 4379         |\n",
      "| n_updates          | 30           |\n",
      "| policy_entropy     | 5.7476115    |\n",
      "| policy_loss        | -0.005122279 |\n",
      "| serial_timesteps   | 3000         |\n",
      "| time_elapsed       | 14           |\n",
      "| total_timesteps    | 60000        |\n",
      "| value_loss         | 35.03167     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0034743524  |\n",
      "| clipfrac           | 0.033999987   |\n",
      "| explained_variance | 0.115         |\n",
      "| fps                | 4248          |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 5.8618746     |\n",
      "| policy_loss        | -0.0055111833 |\n",
      "| serial_timesteps   | 4000          |\n",
      "| time_elapsed       | 18.9          |\n",
      "| total_timesteps    | 80000         |\n",
      "| value_loss         | 89.857315     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0033584186  |\n",
      "| clipfrac           | 0.033374995   |\n",
      "| explained_variance | 0.162         |\n",
      "| fps                | 4238          |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 5.858222      |\n",
      "| policy_loss        | -0.0037420772 |\n",
      "| serial_timesteps   | 5000          |\n",
      "| time_elapsed       | 23.5          |\n",
      "| total_timesteps    | 100000        |\n",
      "| value_loss         | 18.55569      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0020178838  |\n",
      "| clipfrac           | 0.014874998   |\n",
      "| explained_variance | 0.159         |\n",
      "| fps                | 4203          |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 5.9416823     |\n",
      "| policy_loss        | -0.0038845674 |\n",
      "| serial_timesteps   | 6000          |\n",
      "| time_elapsed       | 28.3          |\n",
      "| total_timesteps    | 120000        |\n",
      "| value_loss         | 29.083706     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002256311   |\n",
      "| clipfrac           | 0.016124997   |\n",
      "| explained_variance | 0.1           |\n",
      "| fps                | 3926          |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 5.958098      |\n",
      "| policy_loss        | -0.0025491365 |\n",
      "| serial_timesteps   | 7000          |\n",
      "| time_elapsed       | 32.9          |\n",
      "| total_timesteps    | 140000        |\n",
      "| value_loss         | 82.61167      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0041988203  |\n",
      "| clipfrac           | 0.041874986   |\n",
      "| explained_variance | 0.225         |\n",
      "| fps                | 4316          |\n",
      "| n_updates          | 80            |\n",
      "| policy_entropy     | 6.0810843     |\n",
      "| policy_loss        | -0.0049579674 |\n",
      "| serial_timesteps   | 8000          |\n",
      "| time_elapsed       | 37.6          |\n",
      "| total_timesteps    | 160000        |\n",
      "| value_loss         | 16.780853     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0061664926  |\n",
      "| clipfrac           | 0.075374976   |\n",
      "| explained_variance | 0.695         |\n",
      "| fps                | 4279          |\n",
      "| n_updates          | 90            |\n",
      "| policy_entropy     | 6.158255      |\n",
      "| policy_loss        | -0.0063901236 |\n",
      "| serial_timesteps   | 9000          |\n",
      "| time_elapsed       | 42.3          |\n",
      "| total_timesteps    | 180000        |\n",
      "| value_loss         | 0.23224778    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.003912896   |\n",
      "| clipfrac           | 0.05125       |\n",
      "| explained_variance | 0.405         |\n",
      "| fps                | 4409          |\n",
      "| n_updates          | 100           |\n",
      "| policy_entropy     | 6.2623696     |\n",
      "| policy_loss        | -0.0021419062 |\n",
      "| serial_timesteps   | 10000         |\n",
      "| time_elapsed       | 46.8          |\n",
      "| total_timesteps    | 200000        |\n",
      "| value_loss         | 15.499097     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.003828296   |\n",
      "| clipfrac           | 0.038749985   |\n",
      "| explained_variance | 0.776         |\n",
      "| fps                | 4401          |\n",
      "| n_updates          | 110           |\n",
      "| policy_entropy     | 6.308661      |\n",
      "| policy_loss        | -0.0034652178 |\n",
      "| serial_timesteps   | 11000         |\n",
      "| time_elapsed       | 51.3          |\n",
      "| total_timesteps    | 220000        |\n",
      "| value_loss         | 0.13021927    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0047098314  |\n",
      "| clipfrac           | 0.052624978   |\n",
      "| explained_variance | 0.679         |\n",
      "| fps                | 4331          |\n",
      "| n_updates          | 120           |\n",
      "| policy_entropy     | 6.2194886     |\n",
      "| policy_loss        | -0.0045201085 |\n",
      "| serial_timesteps   | 12000         |\n",
      "| time_elapsed       | 55.8          |\n",
      "| total_timesteps    | 240000        |\n",
      "| value_loss         | 0.28072932    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005987193  |\n",
      "| clipfrac           | 0.076124996  |\n",
      "| explained_variance | 0.595        |\n",
      "| fps                | 4322         |\n",
      "| n_updates          | 130          |\n",
      "| policy_entropy     | 6.2718554    |\n",
      "| policy_loss        | -0.006179926 |\n",
      "| serial_timesteps   | 13000        |\n",
      "| time_elapsed       | 60.4         |\n",
      "| total_timesteps    | 260000       |\n",
      "| value_loss         | 0.09105627   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0049561015 |\n",
      "| clipfrac           | 0.05975      |\n",
      "| explained_variance | 0.496        |\n",
      "| fps                | 4343         |\n",
      "| n_updates          | 140          |\n",
      "| policy_entropy     | 6.259331     |\n",
      "| policy_loss        | -0.005473223 |\n",
      "| serial_timesteps   | 14000        |\n",
      "| time_elapsed       | 64.9         |\n",
      "| total_timesteps    | 280000       |\n",
      "| value_loss         | 14.021634    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0048091793  |\n",
      "| clipfrac           | 0.058375      |\n",
      "| explained_variance | 0.478         |\n",
      "| fps                | 4138          |\n",
      "| n_updates          | 150           |\n",
      "| policy_entropy     | 6.299682      |\n",
      "| policy_loss        | -0.0068048304 |\n",
      "| serial_timesteps   | 15000         |\n",
      "| time_elapsed       | 69.4          |\n",
      "| total_timesteps    | 300000        |\n",
      "| value_loss         | 28.26031      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0056112404  |\n",
      "| clipfrac           | 0.065625      |\n",
      "| explained_variance | 0.593         |\n",
      "| fps                | 4278          |\n",
      "| n_updates          | 160           |\n",
      "| policy_entropy     | 6.315803      |\n",
      "| policy_loss        | -0.0061810487 |\n",
      "| serial_timesteps   | 16000         |\n",
      "| time_elapsed       | 74            |\n",
      "| total_timesteps    | 320000        |\n",
      "| value_loss         | 15.064577     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0042765616  |\n",
      "| clipfrac           | 0.047374982   |\n",
      "| explained_variance | 0.592         |\n",
      "| fps                | 4536          |\n",
      "| n_updates          | 170           |\n",
      "| policy_entropy     | 6.3574185     |\n",
      "| policy_loss        | -0.0020886662 |\n",
      "| serial_timesteps   | 17000         |\n",
      "| time_elapsed       | 78.5          |\n",
      "| total_timesteps    | 340000        |\n",
      "| value_loss         | 10.198426     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002369236   |\n",
      "| clipfrac           | 0.013999997   |\n",
      "| explained_variance | 0.634         |\n",
      "| fps                | 3974          |\n",
      "| n_updates          | 180           |\n",
      "| policy_entropy     | 6.4151473     |\n",
      "| policy_loss        | -0.0012752062 |\n",
      "| serial_timesteps   | 18000         |\n",
      "| time_elapsed       | 83.2          |\n",
      "| total_timesteps    | 360000        |\n",
      "| value_loss         | 99.050285     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.004785506  |\n",
      "| clipfrac           | 0.054249994  |\n",
      "| explained_variance | 0.637        |\n",
      "| fps                | 4348         |\n",
      "| n_updates          | 190          |\n",
      "| policy_entropy     | 6.4448004    |\n",
      "| policy_loss        | -0.004814998 |\n",
      "| serial_timesteps   | 19000        |\n",
      "| time_elapsed       | 87.9         |\n",
      "| total_timesteps    | 380000       |\n",
      "| value_loss         | 9.371837     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0031351917 |\n",
      "| clipfrac           | 0.029499998  |\n",
      "| explained_variance | 0.505        |\n",
      "| fps                | 3818         |\n",
      "| n_updates          | 200          |\n",
      "| policy_entropy     | 6.5110054    |\n",
      "| policy_loss        | -0.004275416 |\n",
      "| serial_timesteps   | 20000        |\n",
      "| time_elapsed       | 92.5         |\n",
      "| total_timesteps    | 400000       |\n",
      "| value_loss         | 112.14812    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0077388086 |\n",
      "| clipfrac           | 0.10237499   |\n",
      "| explained_variance | 0.872        |\n",
      "| fps                | 4770         |\n",
      "| n_updates          | 210          |\n",
      "| policy_entropy     | 6.598577     |\n",
      "| policy_loss        | -0.005838852 |\n",
      "| serial_timesteps   | 21000        |\n",
      "| time_elapsed       | 97.2         |\n",
      "| total_timesteps    | 420000       |\n",
      "| value_loss         | 0.20230997   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015224798  |\n",
      "| clipfrac           | 0.005499999   |\n",
      "| explained_variance | 0.677         |\n",
      "| fps                | 4016          |\n",
      "| n_updates          | 220           |\n",
      "| policy_entropy     | 6.592302      |\n",
      "| policy_loss        | -0.0016454074 |\n",
      "| serial_timesteps   | 22000         |\n",
      "| time_elapsed       | 102           |\n",
      "| total_timesteps    | 440000        |\n",
      "| value_loss         | 69.84895      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0054745288 |\n",
      "| clipfrac           | 0.07000001   |\n",
      "| explained_variance | 0.802        |\n",
      "| fps                | 4378         |\n",
      "| n_updates          | 230          |\n",
      "| policy_entropy     | 6.635955     |\n",
      "| policy_loss        | -0.004210406 |\n",
      "| serial_timesteps   | 23000        |\n",
      "| time_elapsed       | 106          |\n",
      "| total_timesteps    | 460000       |\n",
      "| value_loss         | 13.780596    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0042439443  |\n",
      "| clipfrac           | 0.047124982   |\n",
      "| explained_variance | 0.577         |\n",
      "| fps                | 4295          |\n",
      "| n_updates          | 240           |\n",
      "| policy_entropy     | 6.714938      |\n",
      "| policy_loss        | -0.0047074454 |\n",
      "| serial_timesteps   | 24000         |\n",
      "| time_elapsed       | 111           |\n",
      "| total_timesteps    | 480000        |\n",
      "| value_loss         | 34.63664      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0068796775 |\n",
      "| clipfrac           | 0.085875005  |\n",
      "| explained_variance | 0.752        |\n",
      "| fps                | 4478         |\n",
      "| n_updates          | 250          |\n",
      "| policy_entropy     | 6.740255     |\n",
      "| policy_loss        | -0.005533158 |\n",
      "| serial_timesteps   | 25000        |\n",
      "| time_elapsed       | 116          |\n",
      "| total_timesteps    | 500000       |\n",
      "| value_loss         | 0.44289112   |\n",
      "-------------------------------------\n",
      "CPU times: user 2min 47s, sys: 33.2 s, total: 3min 20s\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fc72c09c8d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = PPO2(MlpPolicy, env, n_steps=int(2000/num_cpu), verbose=1, nminibatches=20)\n",
    "model.learn(total_timesteps=500000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo2_parallel_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BipedalWalker-v2')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO2.load(\"ppo2_parallel_test\", env=env, nminibatches=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -36.5 Num episodes: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-36.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_2(model, 10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
